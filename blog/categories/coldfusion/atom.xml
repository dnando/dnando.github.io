<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Coldfusion | Nando @ Aria Media]]></title>
  <link href="http://dnando.github.io/blog/categories/coldfusion/atom.xml" rel="self"/>
  <link href="http://dnando.github.io/"/>
  <updated>2015-01-08T12:18:48+01:00</updated>
  <id>http://dnando.github.io/</id>
  <author>
    <name><![CDATA[Nando @ Aria Media]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Cannot Find Template CF11]]></title>
    <link href="http://dnando.github.io/blog/2015/01/08/cannot-find-template-cf11/"/>
    <updated>2015-01-08T10:05:36+01:00</updated>
    <id>http://dnando.github.io/blog/2015/01/08/cannot-find-template-cf11</id>
    <content type="html"><![CDATA[<p>Charlie Arehart has a now famous series of talks he presents titled &ldquo;Hidden Gems in ColdFusion xx&rdquo;. I&rsquo;m not sure what the opposite of a &ldquo;gem&rdquo; is. For now, a turd will do. If someone has a better suggestion, let me know.</p>

<h1>Hidden Turd in ColdFusion 11</h1>

<p>I&rsquo;ve recently moved a production application from CF9 to CF11. I didn&rsquo;t catch all the compatibility issues in my testing, so users have been reporting minor bugs and I&rsquo;ve been fixing them and the uploading them to the CF11 server as necessary. Yesterday, late in the afternoon, I uploaded a template with a very minor change to it and got a cannot find template error. Actually it was a cannot find component error. After repeated attempt to replace the file, and careful double checking (it was in the right place, I could find and read the file via the command line) to try and work around it, I changed another template. Now CF couldn&rsquo;t find that one either. Huh???</p>

<p>Nothing I did for the next 8 or 9 hours helped. The template was obviously in the right location. It simply didn&rsquo;t make any sense. I ran through permissions issues, hard disk failure issues, considered cloning the server, wondered how the fact that I had just installed SSL certs might have somehow caused CF to not find a template I had just changed, bizarre as that might seem, thought about updating the JVM or removing the certs from the java keystore, looked at permission issues again, checked and rechecked which user CF was running under, the group it was assigned to, considered whether the server had been hacked somehow, planned how I was going to roll back the entire application to CF9 and shift the data that had changed, thought about switching to Railo and telling my clients they simply have to bear with me while I work through some compatibility issues. I had to get the server back up by this morning. My clients run their businesses with it. I tried yelling at the server through my monitor. &ldquo;Bloody well just look, open your eyes, dammit!! It&rsquo;s right there in front of your nose!!!&rdquo; Didn&rsquo;t help.</p>

<p>The bigger problem was that it broke the application - it was no longer possible to login - and as I said, that my clients depend on it to run their businesses. I needed it up again by this morning. #$%&amp;@!!!!</p>

<p>In the end, I got lucky with my Google foo and found someone else who has run into this issue. Turns out the problem was an option in ColdFusion administrator. The &ldquo;Save class files&rdquo; option was checked by default on install. I didn&rsquo;t change any settings in the Caching section on install, assuming that the defaults would be &ldquo;safe&rdquo;, they would not cache anything in a way that would make the server &ldquo;un-updateable&rdquo;. I was wrong. The defaults can easily break your application, and leave you no clue at all as to why.</p>

<p>I needed to uncheck it, restart CF, and then the app worked again.</p>

<p>The text next to the checkbox says this:</p>

<p><em>When you select this option, the class files generated by ColdFusion are saved to disk for reuse after the server restarts. Adobe recommends this for production systems. During development, Adobe recommends that you do not select this option.</em></p>

<p>It should say:</p>

<p><em>When you select this option, any changes you make to your files may break your application. The error messages you will get will give you no clue at all what the underlying cause is - namely this checkbox enabling the poorly designed functionality behind it.</em></p>

<p>I expect options for production systems to make CF more performant, stable or secure. Options that potentially take production applications down with no warning, rhyme or reason are neither expected nor welcome. Given that I now am fully aware of the consequences of checking this box, I would recommend leaving it always unchecked. Otherwise, every time I need to make a minor change to a production server I have to remember to uncheck it, reboot the server, make my change, check it again, and perhaps reboot the server again. How does that improve the experience of my users? And if I somehow forget this arcane procedure, whatever it actually is, and take the app down again with a minor change, perhaps for hours and even days, it&rsquo;s even worse!</p>

<p>Someone will invariably blame me. I should have known this - and remembered it. Well, maybe this blog post will help both me and perhaps others in this regard. That said, I think the fact that this option causes CF to break production applications is a <a href="https://bugbase.adobe.com/index.cfm?event=bug&amp;id=3917793">bug.</a> Feel free to vote for it if you agree.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Nginx With ColdFusion or Railo]]></title>
    <link href="http://dnando.github.io/blog/2015/01/05/advantages-of-nginx/"/>
    <updated>2015-01-05T20:26:47+01:00</updated>
    <id>http://dnando.github.io/blog/2015/01/05/advantages-of-nginx</id>
    <content type="html"><![CDATA[<p>Over the past few weeks I&rsquo;ve installed and experimented with the Nginx webserver. At this point it seems to me there are some significant advantages to using Nginx over Apache, advantages that aren&rsquo;t often highlighted, specifically when using either ColdFusion or Railo as your application server.</p>

<p>First up, it was very easy to install, start, and enable so that it always starts at boot time. These are the commands I used for CentOS 7, adapt as necessary for your operating system:</p>

<pre><code>rpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm
yum install nginx
systemctl start nginx.service
systemctl enable nginx.service
</code></pre>

<p>I could then browse to the server ip and see the Nginx welcome page.</p>

<p>It then took me a bit of time for me to grok how the configuration setup works. However, compared to Apache&rsquo;s massive conf file, the fact that I could easily see the entire main configuration in a single screen immediately put me at ease. Basically, Nginx has a main config file, located at /etc/nginx/nginx.conf on my CentOS install, which can be extended with includes. Before I started messing with it, the main conf file looked something like this:</p>

<pre><code class="">user  nginx;
worker_processes  1;
error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;

events {
    worker_connections  1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    include /etc/nginx/conf.d/*.conf;
}
</code></pre>

<p>&hellip; and the default site conf file, which is picked up by the include at the bottom of the main conf file above, looked like this:</p>

<pre><code>server {
    listen       80;
    server_name  localhost;

    #charset koi8-r;
    #access_log  /var/log/nginx/log/host.access.log  main;

    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
    }

    #error_page  404              /404.html;

    # redirect server error pages to the static page /50x.html
    #
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }

    # proxy the PHP scripts to Apache listening on 127.0.0.1:80
    #
    #location ~ \.php$ {
    #    proxy_pass   http://127.0.0.1;
    #}

    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
    #
    #location ~ \.php$ {
    #    root           html;
    #    fastcgi_pass   127.0.0.1:9000;
    #    fastcgi_index  index.php;
    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
    #    include        fastcgi_params;
    #}

    # deny access to .htaccess files, if Apache's document root
    # concurs with nginx's one
    #
    #location ~ /\.ht {
    #    deny  all;
    #}
}
</code></pre>

<p>Note the asterik syntax in the include at the bottom of the main conf file:
<code>include /etc/nginx/conf.d/*.conf;</code>.
Effectively, any .conf file you drop in that directory becomes part of the configuration ( specifically of the http{} block ).</p>

<p>Note also that there are semicolons at the end of every setting. If you see errors when reloading conf files using the command <code>nginx -s reload</code>, look for missing semicolons.</p>

<p>In a nutshell, Nginx&rsquo;s configuration is a simple nested structure, like this:</p>

<pre><code>nginx global settings

events {

}

http {

    server {
        listen 80;   # port to listen on
        server_name domain.com *.domain.com domain.net *.domain.net;
        root /var/www/domain;  #absolute path to root directory of website files

        location /downloads {
            # specific settings for a file system location relative to the root
            # which in this example would be /var/www/domain/downloads
        }

        location ~* \.(?:ico|css|js|gif|jpe?g|png)$ {
            # specific settings for files ending in suffixes .ico, .css, .js, gif, etc
            # defined using a regex, under the root directory defined in the server block
        }

        location / {
            # general settings for all files under/var/www/domain in this example
            # in this example only for those files that do not match the more specific location directives above
        }

        location = / {
            # this directive is triggered when only the domain is specified in the url
            # in this example for the url http://example.com
        }

    }

    server {
        # configuration for another virtual server, 
        # defined by a unique server_name or listen directive
    }

}
</code></pre>

<p>Each server block defines a virtual server, similar to a virtual host in Apache. The <code>server_name</code> directive takes a space delimited list of domains, which can include an asterisk as a wildcard character, replacing the first or last part of a name, to specify for instance any subdomain or TLD. Note that a directive like <code>server_name example.com *.example.com</code> can be also written with the shorthand expression <code>server_name .example.com</code></p>

<p>Nginx selects and processes locations within a server block using the most specific match, with regexes taking precedence, followed by the longest matching prefix. So in the above example, Nginx would process a file named myImage.jpg using the second location directive, a file in the downloads directory named myInfo.pdf using the first location directive, a file named index.htm ( or index.cfm ) using the third location directive, and a request to the root of the domain, say to <a href="http://domain.com/,">http://domain.com/,</a> with the last location directive, where the addition of the &ldquo;=&rdquo; sign specifies an exact match.</p>

<p>See the <a href="http://nginx.com/resources/admin-guide/web-server/">Nginx Web Server configuration guide</a> for more details.</p>

<p>To use Nginx with either ColdFusion or Railo, the <code>proxy_pass</code> directive is used, as in the following example:</p>

<pre><code>server {
    listen 80;   # port to listen on
    server_name domain.com *.domain.com domain.net *.domain.net;
    root /var/www/domain;  #absolute path to root directory of website files

    location /downloads {
        # specific settings for a file system location relative to the root
        # which in this example would be /var/www/domain/downloads
    }

    location ~* \.(?:ico|css|js|gif|jpe?g|png)$ {
        # specific settings for files ending in suffixes .ico, .css, .js, gif, etc
        # defined using a regex, under the root defined in the server block
    }

    location / {
        proxy_pass  http://127.0.0.1:8500/domain/;
    }

}
</code></pre>

<p>In the above example, Nginx passes the request to ColdFusion, running on the same server, via port 8500. It gets the response back from CF, immediately terminates the connection to CF so it is available to handle the next request, and then serves the static files using the settings in the second location directive, along with the rendered html from ColdFusion to the user that made the request. Note that this configuration assumes that you&rsquo;ve <a href="http://dnando.github.io/blog/2014/12/04/change-location-of-cf11-webroot/">changed the location of the CF webroot</a>.</p>

<p>The first advantage here is that there is no connector needed between ACF or Railo and the webserver. We don&rsquo;t need to install a connector as part of the initial server setup, and we avoid any bugs or configuration problems that might crop up with these connectors. We also avoid the necessity to sometimes manually reinstall connectors when updating ACF/Railo. All that is needed is to add the proxy_pass directive and reload the configuration using <code>nginx -s reload</code>.</p>

<p>The second advantage is that as long as you have a firewall in place that only allows public access via ports 80, ( plus maybe port 443, and whatever port you are using for ssh access), your ACF or Railo server is secured, simply because without a connector between the webserver and your application server, there is no direct access via port 80 or port 443 to your application server. In our example above, anyone browsing to domain.com/CFIDE/administrator/ will get a 404 error. The CFIDE directory isn&rsquo;t in the root specified. Port 8500 is closed, so ip:8500/CFIDE/administrator/ won&rsquo;t return a response. The ACF admin directory is not contained in the default site Nginx root, so ip:/CFIDE/administrator/, for instance, will simply return a 404.</p>

<p>How do you gain access to the admin areas of ColdFusion or Railo on a remote server if ports 8500 or port 8888 are closed? Simple. Use <a href="http://dnando.github.io/blog/2014/11/04/ssh-tunneling-coldfusion-lockdown-technique/">SSH Tunneling</a>.</p>

<p>In the event that the CFIDE, WEB-INF, or railo-context directories are exposed through a particular configuration setup in a particular server block, there is a simple way to handle this using location directives that can be set globally or included in each server block necessary, for example:</p>

<pre><code>location ~ /WEB-INF/  { access_log off; log_not_found off; deny all; }
location ~ /META-INF/  { access_log off; log_not_found off; deny all; }
</code></pre>

<p>or</p>

<pre><code>location ~ /WEB-INF/  { return 404; }
location ~ /META-INF/  { return 404; }
</code></pre>

<p>or</p>

<pre><code>location ~ /CFIDE/ {
    deny all;
    allow 127.0.0.1;
    }
</code></pre>

<p>Very few developers spend significant time configuring servers. Hence, it often may happen that the servers we maintain for our clients are not as secure as they could be. The simplicity with which we can secure a ColdFusion server behind Nginx seems a definite advantage.</p>

<p>However, the biggest advantage, to me, seems to be the ease of configuring strong SSL https security on Nginx. Because Nginx uses a reverse proxy setup, Nginx can be configured to handle the https connection with the requestor in isolation. What this implies is that SSL certificates do not need to be imported into the Java keystore. Nor do your SSL certs need to be reimported every time the JVM is updated. Of course, if you require a very secure setup, in a load balanced configuration to multiple application servers, you might need to ensure an SSL connection between Nginx and ColdFusion / Railo. But if, for instance, Nginx and ColdFusion / Railo are located on the same server, or you trust the internal network, this would not be necessary.</p>

<p>Following this <a href="https://raymii.org/s/tutorials/Strong_SSL_Security_On_nginx.html">excellent guide</a> by Remy van Elst, I was able to relatively easily setup SSL for a web application to an A+ level as graded by <a href="https://www.ssllabs.com/ssltest/index.html">Qualys SSL Labs</a>. Here&rsquo;s what the SSL portion of my Nginx configuration looks like:</p>

<pre><code>server {
    server_name  domain.com;
    listen  443 ssl;

    ssl_certificate     /etc/ssl/certs/domain_com.crt;
    ssl_certificate_key /etc/ssl/certs/domain_com.key;

    keepalive_timeout   70;
    ssl_ciphers         'AES256+EECDH:AES256+EDH:!aNULL';

    ssl_prefer_server_ciphers   on;
    ssl_dhparam         /etc/ssl/certs/dhparam.pem;

    ssl_session_cache shared:SSL:10m;
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;

    ssl_stapling on;
    ssl_stapling_verify on;
    resolver 8.8.8.8 8.8.4.4 valid=300s;
    resolver_timeout 5s;

    add_header Strict-Transport-Security max-age=345600;
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;

}
</code></pre>

<p>Note that I&rsquo;ve reduced the max-age value of the add_header Strict-Transport-Security directive to four days from what Remy has recommended, over uncertainty how this will play out when certificates are updated. I understand that this directive will force user agents to use https for the duration of the value set. Note that it will be updated into the future every time the header is sent to the browser.</p>

<p>There are 3 aspects of this configuration that require a bit of extra work on your part, besides simply copying, pasting and adjusting the above example. One is that if your SSL certificate provider has also issued intermediate and root certificates, you will need to concatenate these into one file. Your domain certificate must come first, followed by the intermediate certificates, and finally the root certificate at the end. The easiest way to do this is to create a blank text file, and copy and paste the contents of the certificates into it. Save it and upload it to the chosen location on your server, along with the private key. Point to the location of the concatenated cert in the Nginx config file using the ssl_certificate directive. Point to the location of the private key using the ssl_certificate_key directive.</p>

<p>On Linux, you should secure the key by running chmod 600 on the ssl directory that contains the certificate files and chmod 400 on the private key file itself.</p>

<p>To generate the file referred to in the ssl_dhparam directive in the above example, it is necessary to cd to your ssl certs directory and run the following command, as explained in <a href="https://raymii.org/s/tutorials/Strong_SSL_Security_On_nginx.html">Remy&rsquo;s guide</a> in the Forward Secrecy &amp; Diffie Hellman Ephemeral Parameters section:</p>

<pre><code>cd /etc/ssl/certs
openssl dhparam -out dhparam.pem 4096
</code></pre>

<p>You will be warned  that &ldquo;this will take awhile&rdquo;. Remy doesn&rsquo;t mention this, but be prepared for it to take a relatively long time, perhaps an hour or so.</p>

<p>Once you have ssl configured and working, you probably want to redirect any traffic trying to access the site via insecure http to secure https. Here&rsquo;s how to configure that:</p>

<pre><code>server {
    server_name  domain.com;
    listen  80;
    return  301 https://$server_name$request_uri;
}
</code></pre>

<p>I already mentioned what I think is the biggest advantage, the ease with which one can configure SSL. However, there is one other advantage I&rsquo;d like to mention that may trump that, the ability to easily configure Nginx for both load balancing and hot swapping of application servers. Here&rsquo;s how to do that using the upstream directive:</p>

<pre><code>upstream    cf_servers {
    #ip_hash;                   ## uncomment ip_hash for load balancing         
    server          127.0.0.1:8500;
    #server         192.168.0.20:8500;  ## add more application servers for load balancing
    keepalive       32;         ## number of upstream connections to keep alive
}

upstream    railo_servers {
    #ip_hash;                   ## uncomment ip_hash for load balancing         
    server          127.0.0.1:8888;
    #server         192.168.0.30:8888;  ## add more application servers for load balancing
    keepalive       32;         ## number of upstream connections to keep alive
}
</code></pre>

<p>Then instead of using the localhost IP address in your proxy_pass directive, use the upstream server name instead, like so:</p>

<pre><code>location / {
    proxy_pass  http://cf_servers/domain/;
}
</code></pre>

<p>If you get caught in a bind and can&rsquo;t use ColdFusion for some reason, then hot swapping an application over to Railo is as simply as changing the above to this:</p>

<pre><code>location / {
    proxy_pass  http://railo_servers/domain/;
}
</code></pre>

<p>Or if you find one of your web properties suddenly inundated with traffic, using the upstream directive, your webserver is already set up for load balancing. You&rsquo;d simply need to clone a few servers, boot them up, and add them to the upsteam directive. The ip_hash directive is a way to enable sticky sessions, to ensure a visitor is always routed to the same server.</p>

<p>A few more configuration options and details should be mentioned.</p>

<p>One is that it is also possible, and perhaps preferable, to configure the path to a website&rsquo;s files within Tomcat&rsquo;s server.xml file, rather than specifying it in the Nginx proxy_pass directive.</p>

<pre><code>&lt;Host name="domain.com" appBase="webapps"&gt;
    &lt;Context path="" docBase="/var/sites/domain.com" /&gt;
    &lt;Alias&gt;www.domain.com&lt;/Alias&gt;
&lt;/Host&gt;
</code></pre>

<p>With the path to the website&rsquo;s files configured in server.xml, the path to the website&rsquo;s files is not appended to the proxy_pass directive, so it would look like this:</p>

<pre><code>server {
    listen 80;
    server_name .domain.com;
    root /var/www/domain; 

    location ~* \.(?:ico|css|js|gif|jpe?g|png)$ {
        # specific settings for files ending in suffixes .ico, .css, .js, gif, etc
    }

    location / {
        proxy_pass  http://railo_servers/;
    }

}
</code></pre>

<p>For this to work, Nginx needs to pass the host name to the app server used, either Railo or ColdFusion. Your application may also require this information. Here is a suggested set of directives to accomplish this:</p>

<pre><code>    proxy_http_version  1.1;
    proxy_set_header    Connection "";
    proxy_set_header    Host                $host;
    proxy_set_header    X-Forwarded-Host    $host;
    proxy_set_header    X-Forwarded-Server  $host;
    proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;     ## CGI.REMOTE_ADDR
    proxy_set_header    X-Forwarded-Proto   $scheme;                        ## CGI.SERVER_PORT_SECURE
    proxy_set_header    X-Real-IP           $remote_addr;
    expires             epoch;
</code></pre>

<p>&hellip; which could be placed in a separate conf file and included with each proxy_pass directive, like so:</p>

<pre><code>location / {
    proxy_pass  http://railo_servers/;
    include     /var/inc/nginx-cf-proxy-settings.conf;
}
</code></pre>

<p>If you are using Railo, adding a host configuration block to server.xml will cause Railo to create a WEB-INF directory under the docBase path specified along with an additional context. You&rsquo;d then want to block public access to that directory in some way as I&rsquo;ve explained above.</p>

<p>You can also use a regex to ensure you only pass CFML templates to Railo or ColdFusion, as the following example demonstrates:</p>

<pre><code>location ~ \.(cfm|cfml|cfc)$ {
    proxy_pass  http://railo_servers/;
    include     /var/inc/nginx-cf-proxy-settings.conf;
}
</code></pre>

<p>You can put whatever file extensions you&rsquo;d like Railo / ACF to process in the pipe delimited list within the regex, so <code>~ \.(cfm|cfml|cfc)$</code> or <code>~ \.(cfm|cfml|htm|html)$</code> could be used, for example.</p>

<p>A couple of small gotcha&rsquo;s I ran into setting the path to the website&rsquo;s files in the proxy_pass directive. One is that directories with dots in them can confuse mappings. The solution I used was to remove the dots from directory names and use hyphens instead ( my-domain-com ). I also had trouble with redirects in FW/1, since they rely on the value of cgi.script_name. The simple solution was to change the baseURL parameter of FW/1&rsquo;s config to <code>baseURL = ''</code> from the default <code>baseURL = 'useCgiScriptName'</code>. Problems such as these might be avoided by using the server.xml configuration option.</p>

<p>I have 2 production servers running Nginx at the moment, one ACF and one Railo server, and so far it seems to be working very well. I&rsquo;m particularly happy with the choice because Nginx has a very small memory footprint, which leaves more memory available for the JVM, which indeed yet another advantage.</p>

<p>References:</p>

<ol>
<li><a href="http://nginx.com/resources/admin-guide/web-server/">Nginx Web Server configuration guide</a></li>
<li><a href="https://raymii.org/s/tutorials/Strong_SSL_Security_On_nginx.html">Remy van Elst Strong SSL Security on Nginx</a></li>
<li><a href="https://gist.github.com/igal-getrailo/6981111">Igal&rsquo;s Nginx config example</a></li>
<li><a href="http://www.amazon.com/Mastering-Nginx-Dimitri-Aivaliotis/dp/1849517444">Mastering NGINX by Dimitri Aivaliotis</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Change Location of ColdFusion Webroot]]></title>
    <link href="http://dnando.github.io/blog/2014/12/04/change-location-of-cf11-webroot/"/>
    <updated>2014-12-04T18:12:08+01:00</updated>
    <id>http://dnando.github.io/blog/2014/12/04/change-location-of-cf11-webroot</id>
    <content type="html"><![CDATA[<p>I&rsquo;m in the process of preparing a server to test CF11 with nginx as the front end webserver. Since nginx will act as a reverse proxy for any files that need to be processed by CF, essentially .cfm files, and serve any other assets directly, images, css and js files, etc, I want to relocate the ColdFusion webroot to a directory outside of the cf installation directories. A little googling led me to a <a href="http://blog.bittersweetryan.com/2012/02/changing-webroot-of-coldfusion-zeus.html">old blog post</a> that outlined the process in sufficient detail that I got it working on the first shot. Thanks Ryan! This post is both to refresh the collective knowledge cache and affirm that the technique works on CF11 as well as CF10.</p>

<p>The first step is to locate the server.xml file, which you will find at</p>

<p><cfInstallationDirectory>/cfusion/runtime/conf/server.xml</p>

<p>Make a backup of it. If something goes wrong, you can use the backup to restore CF to a working state again. Note that CF needs to be able to locate the CFIDE and WEB-INF directories to function properly, and these are both located with in the default webroot location. So make a backup of server.xml before proceeding.</p>

<p>Open server.xml for editing, scroll down to the bottom of the file where you should find the following line commented out:</p>

<p>&#8220;`</p>

<!-- <Context path="/" docBase="<cf_home>\wwwroot&#8221; WorkDir=&#8221;<cf_home>\runtime\conf\Catalina\localhost\tmp&#8221; ></Context>  &#8211;>


<pre><code>
Assuming the installation directory is /opt/cf11, so that I can give a concrete example, uncomment that line and adapt it to the following model, which is working on my CF11 installation:
</code></pre>

<p><Context path="/" docBase="/var/www" WorkDir="/opt/cf11/cfusion/runtime/conf/Catalina/localhost/tmp" aliases="/CFIDE=/opt/cf11/cfusion/wwwroot/CFIDE,/WEB-INF=/opt/cf11/cfusion/wwwroot/WEB-INF"></Context>
&#8220;`</p>

<p>The docBase is the new webroot location, which must already exist, but can be of your choice. WorkDir points to an existing location in the installation directories. The aliases are essential, so that CF can find the CFIDE and WEB-INF directories. Adjust the slant of the slashes depending on your operating system, Windows or Linux. Use absolute paths for these settings, so on a Windows server, they would likely begin with a drive letter.</p>

<p>After you&rsquo;ve edited and saved server.xml, restart ColdFusion, place some cf code in the docBase directory, and browse to it via localhost:8500/ to make sure it works. Also check if you can still access the CF admin panel at localhost:8500/CFIDE/administrator/, which CF should find via the <em>aliases=</em> declaration. If both those tests succeed, you should be good to go!</p>

<p>References:</p>

<ol>
<li><a href="http://blog.bittersweetryan.com/2012/02/changing-webroot-of-coldfusion-zeus.html">http://blog.bittersweetryan.com/2012/02/changing-webroot-of-coldfusion-zeus.html</a></li>
<li><a href="http://blogs.coldfusion.com/post.cfm/getting-started-with-tomcat-in-coldfusion-10">http://blogs.coldfusion.com/post.cfm/getting-started-with-tomcat-in-coldfusion-10</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSH Tunneling - ColdFusion Lockdown Technique]]></title>
    <link href="http://dnando.github.io/blog/2014/11/04/ssh-tunneling-coldfusion-lockdown-technique/"/>
    <updated>2014-11-04T14:40:42+01:00</updated>
    <id>http://dnando.github.io/blog/2014/11/04/ssh-tunneling-coldfusion-lockdown-technique</id>
    <content type="html"><![CDATA[<p>The ColdFusion and Railo Lockdown Guides recommend that access is restricted to all administrative areas of the server. This is especially important to do because many security vulnerabilities have been discovered that exploit open access to admin directories. It is fairly easy to accomplish, using a directive in the Apache configuration for example. It would look something like this on ACF:</p>

<pre><code>&lt;Location /CFIDE&gt;
    Order Deny,Allow
    Deny from All
&lt;/Location&gt;
</code></pre>

<p>or this on Railo:</p>

<pre><code>&lt;Location /railo-context&gt;
    Order Deny,Allow
    Deny from all
&lt;/Location&gt;
</code></pre>

<p>So far so good, but now anyone needing to administer the server can&rsquo;t login. They will be denied access by the web server. There are various recommendations for allowing only selective access, for instance from a given fixed IP address at the office of the administrator:</p>

<pre><code>&lt;Location /railo-context&gt;
    Order Deny,Allow
    Deny from all
    Allow from 84.16.156.99
&lt;/Location&gt;
</code></pre>

<p>But what if the server administrator(s) is/are out of the office when they need access to the server? Away at a conference, at a client&rsquo;s office, or at home? And what if your office doesn&rsquo;t have a fixed IP address? Should you get one &hellip; and then have to remember to change the &ldquo;allow from&rdquo; IP address in all of your server configuration files if and when that IP address changes? For a variety of reasons, this doesn&rsquo;t seem ideal.</p>

<p>There&rsquo;s another &ldquo;small&rdquo; problem here. Best security practice dictates that all access to admin areas should be over an encrypted connection. I cannot ensure that the modem installed here in my office, or wherever else I happen to be when needing to admin my servers, a hotel for instance, is not compromised by a packet sniffer. In fact, I recently installed an update on our modem here specifically for a packet sniffing vulnerability, and I only ran across it by chance. No idea how long that remained unpatched, and I&rsquo;m simply not prepared to invest the time to learn how to monitor this sort of thing. This implies that I <em>definitely should</em> install SSL certificates and set up secure https access for all administrative areas on each server I maintain. That&rsquo;s painful.</p>

<p>Put all that together, and it helps to explain why ACF and Railo servers are often not locked down.</p>

<p>Here&rsquo;s where SSH tunneling comes to the rescue. In a nutshell, it allows you to securely browse a remote server as localhost, as if the server was under your desk and your keyboard and monitor where connected to it, even if it&rsquo;s located halfway around the world. The icing on the cake is it is very simple to set up, and the same setup will work for every server you admin!</p>

<p>To use SSH tunneling to gain access to admin areas of your server, the first step to restrict access to any admin area to only localhost, for example:</p>

<p>For ACF:</p>

<pre><code>&lt;Location /CFIDE&gt;
    Order Deny,Allow
    Deny from All
    Allow from localhost
&lt;/Location&gt;
</code></pre>

<p>or for Railo:</p>

<pre><code>&lt;Location /railo-context&gt;
    Order Deny,Allow
    Deny from all
    Allow from localhost
&lt;/Location&gt;
</code></pre>

<p>( While you are at it, restrict port access to only those ports you need to leave exposed, for instance 80, 443 and whatever port you are using for SSH access ).</p>

<p>There are detailed instructions for SSH tunneling all over the web if you want to find out more, but the instructions below should work fine for our purposes.</p>

<ol>
<li><p>In your web browser, configure the proxy settings to point to &ldquo;localhost&rdquo;, a free port on your local machine (we&rsquo;ll use 60001), using SOCKS5. This should work with any browser. Using Firefox as an example, here&rsquo;s how to do that:</p>

<ul>
<li>Go to Preferences</li>
<li>Click the Advanced icon</li>
<li>Click the Network tab</li>
<li>Click the Settings button, across from where it says &ldquo;Configure how Firefox connects to the Internet</li>
<li>Select Manual proxy configuration</li>
<li>In the SOCKS Host field put &ldquo;localhost&rdquo; without the quotation marks</li>
<li>In the Port field put the port number you will use, 60001 in our example</li>
<li>Select SOCKS v5</li>
<li>Click OK</li>
</ul>
</li>
<li><p>ssh into any server you admin using Terminal or Putty, etc.  Use the -D flag set to the same port as above, example: ssh -D 60001 <a href="&#x6d;&#x61;&#x69;&#x6c;&#116;&#x6f;&#58;&#117;&#x73;&#101;&#x72;&#64;&#x31;&#x30;&#50;&#x2e;&#49;&#x30;&#x33;&#x2e;&#49;&#x30;&#56;&#x2e;&#x33;&#x39;">&#x75;&#115;&#x65;&#114;&#x40;&#49;&#x30;&#50;&#46;&#x31;&#x30;&#51;&#x2e;&#49;&#x30;&#x38;&#46;&#51;&#57;</a></p></li>
<li><p>You can now access admin areas of the server in this browser using localhost urls such as <a href="http://127.0.0.1/CFIDE/administrator/enter.cfm,">http://127.0.0.1/CFIDE/administrator/enter.cfm,</a> as long as you remain logged in via SSH. The connection is through an SSH &ldquo;tunnel&rdquo;, so between your local machine and the server, all traffic is encypted.</p></li>
</ol>


<p>Note that the port chosen is arbitrary. It only has to be available and match in both the -D flag and SOCKS port setting. To revert the browser to normal behavior, simply choose No Proxy in the Network Settings dialog.</p>

<p>What I usually do is leave Firefox configured in this way and reserve it only for SSH tunnelling sessions. And again, once a browser is configured with these proxy settings, you can securely browse any server as localhost by SSH&#8217;ing into it with the -D port setting.</p>

<p>Now say you have Fusion Reactor installed and want to ensure access is also restricted. Just leave your firewall configured to leave the ports Fusion Reactor uses closed, and access it, securely, via your SSH tunnel!</p>

<p>Thanks to <a href="https://www.linkedin.com/in/davidjstockton">David Stockton</a>, who until recently worked with the fusion reactor team, for sharing this tip with me.</p>

<p><strong>IMPORTANT NOTE:</strong> If you have difficulty logging in, or maintaining a login, particularly to the ACF admin panel, clear the cookies in the browser you are using for SSH tunneling and try again.</p>

<p>In my case, I ran into this after using this technique to manage multiple instance of ACF, particularly on ACF 11. I could log in to the admin panel successfully, but if I tried to modify anything, set a datasource for instance, I was logged out and the action did not complete. The error log contained the message &ldquo;There was an error while verifying the token. Either the session timed out or un-authenticated access is suspected.&rdquo;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Is This Acceptable?]]></title>
    <link href="http://dnando.github.io/blog/2014/10/17/is-this-acceptable/"/>
    <updated>2014-10-17T14:09:18+02:00</updated>
    <id>http://dnando.github.io/blog/2014/10/17/is-this-acceptable</id>
    <content type="html"><![CDATA[<p>A few days ago, Adobe released <a href="http://blogs.coldfusion.com/post.cfm/updates-for-coldfusion-11-coldfusion-10-and-coldfusion-9-released">updates</a> for CF 9, 10 and 11. I&rsquo;ve been following comments raised about them since, and I&rsquo;m disturbed to see some developers struggling to get their servers patched, especially when applying the update has taken the server down. I don&rsquo;t know if these cases are isolated or might be more widespread, but I find this unacceptable.</p>

<p>I run several instances of ACF on CentOS. I&rsquo;m subscribed to the CentOS-announce Digest mailing list, as I&rsquo;m sure most CentOS server admins are. For many years now, whenever an update is released, perhaps once or twice a week, I ssh directly onto our servers, run yum update, and generally within less than a minute, the update completes. Never once has the process failed. Never once have I seen an incoming email on the CentOS mailing list that someone experienced a server crash, or any other issue for that matter, because of an update.</p>

<p>This is how ColdFusion updates <strong>should</strong> function, flawlessly.</p>

<p>In stark contrast, CF developers have become wary of applying updates. There is a risk that their server will compromised because of the security vulnerability the update is meant to patch, and there seems to be an equal if not greater risk that their server will be compromised, in one way or another, in the update process. CF 10 introduced automated updates, but as we see, the automated update process remains error prone.</p>

<p>It should not be like this. Rather than focusing on new features, the CF dev team needs to focus on getting the update process as flawless as it is on CentOS. What they seem to have lost track of is that, for a start, developers have families to support. Our clients expect us to keep their servers up and running 24/7. Our clients depend on the applications we build to run their businesses. As developers, we <em>cannot</em> afford to experiment on our clients. And yet, when Adobe releases a flawed update that takes servers down, effectively experimenting on us and our clients, <em>oh, look, they are trapped between a security vulerability and a flawed update</em>, the implicit statement received on our end is &ldquo;We don&rsquo;t care if you keep your clients. It does not matter to us at all.&rdquo; Really?</p>

<p>What is even more disturbing is the way the Adobe dev team now uses us as their QA department, as if ColdFusion server was loosely organized open source project among wannabe hackers. It is not disturbing because the CF devs are actively reaching out trying to solve problems that are occurring, asking for logs, error message screenshots, suggesting the possible need to copy and paste jar files from here to there if some functionality is broken, instructing us to manually install the updates one at a time if the automated updater doesn&rsquo;t work, etc. It is because these interchanges should never occur in the first place regarding an update. The update process needs to be flawless, as near to it as possible, so that we can rely on it. Like it is on CentOS. If they can do it, the CF dev team can do it.</p>

<p>The worst, however, is <a href="http://blogs.coldfusion.com/post.cfm/updates-for-coldfusion-11-coldfusion-10-and-coldfusion-9-released#comment-2A6D270F-CEF1-319F-EDCFF7262E950FC0">this</a>, linked for reference but replicated below, an Adobe engineer asking a developer, a paying customer, to effectively crash his server &ldquo;in off peak hours&rdquo; so that he can get at the log files that might reveal what the problem is.</p>

<p><blockquote><p></p></p><p><p>Hi Mark,</p></p><p><p>Of all the things connector logs with debug_level=debug are the most important one&rsquo;s. Till now with all the information you have shared I can tell that there is some problem with shared memory access between worker threads. But to exactly pin point the problem I will be needing the connector logs. I understand it will be difficult for you to do something on production server but it is a must for this problem to be resolved.</p></p><p><p>If possible in off-peak hours, apply the update14 and reconfigure the connector. Once the connector is installed go to connector directory c:\coldfusion10\config\wsconfig\magicnumber\ and open isapi_redirect.properties in notepad.<br/>Edit the line &ldquo;log_level= info&rdquo; and change it to &ldquo;log_level= debug&rdquo; and save the changes. Restart IIS, hit any cfm page and wait for app pool to crash. Once it is crashed take a backup of isapi_redirect.log(created in connector directory) in some other directory like c:\connector_logs\ directory. After the backup you can revert back the changes.<br/>Lastly you have to share this backed up logs with us.</p></p><p><p>Thanks,<br/>Milan.</p></p><p><p></p></blockquote></p>

<p>When I say this is unacceptable, I mean that it is not acceptable for Adobe to use CF developers and their clients as their QA team, especially in that Milan says &ldquo;I understand it will be difficult for you to do something on production server but it is a <em>must</em> for this problem to be resolved.&rdquo; No, it is <strong>not</strong> a must to take down our servers, possibly endangering our client relationships, to fix your bugs.</p>

<p>Yes, this is very complex stuff. But in today&rsquo;s world, that simply means Adobe needs to employ a vastly improved QA strategy than the one they have in place today for ColdFusion releases, especially for the update process itself.</p>
]]></content>
  </entry>
  
</feed>
